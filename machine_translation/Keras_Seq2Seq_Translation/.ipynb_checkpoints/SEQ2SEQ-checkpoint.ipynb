{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 5  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "num_samples = 10000  # Number of samples to train on.\n",
    "# Path to the data txt file on disk.\n",
    "data_path = 'fra-eng/fra.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 10000\n",
      "Number of unique input tokens: 71\n",
      "Number of unique output tokens: 93\n",
      "Max sequence length for inputs: 16\n",
      "Max sequence length for outputs: 59\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the data.\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, _ = line.split('\\t')\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
    "\n",
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
    "    decoder_target_data[i, t:, target_token_index[' ']] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enc-Dec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'lstm_15_1/strided_slice_6:0' shape=(None, 256) dtype=float32>,\n",
       " <tf.Tensor 'lstm_15_1/while:4' shape=(None, 256) dtype=float32>,\n",
       " <tf.Tensor 'lstm_15_1/while:5' shape=(None, 256) dtype=float32>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder(encoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'lstm_16_1/transpose_1:0' shape=(None, None, 256) dtype=float32>,\n",
       " <tf.Tensor 'lstm_16_1/while:4' shape=(None, 256) dtype=float32>,\n",
       " <tf.Tensor 'lstm_16_1/while:5' shape=(None, 256) dtype=float32>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_lstm(decoder_inputs,initial_state=encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_2/truediv:0' shape=(None, None, 93) dtype=float32>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " '!': 1,\n",
       " '$': 2,\n",
       " '%': 3,\n",
       " '&': 4,\n",
       " \"'\": 5,\n",
       " ',': 6,\n",
       " '-': 7,\n",
       " '.': 8,\n",
       " '0': 9,\n",
       " '1': 10,\n",
       " '2': 11,\n",
       " '3': 12,\n",
       " '5': 13,\n",
       " '6': 14,\n",
       " '7': 15,\n",
       " '8': 16,\n",
       " '9': 17,\n",
       " ':': 18,\n",
       " '?': 19,\n",
       " 'A': 20,\n",
       " 'B': 21,\n",
       " 'C': 22,\n",
       " 'D': 23,\n",
       " 'E': 24,\n",
       " 'F': 25,\n",
       " 'G': 26,\n",
       " 'H': 27,\n",
       " 'I': 28,\n",
       " 'J': 29,\n",
       " 'K': 30,\n",
       " 'L': 31,\n",
       " 'M': 32,\n",
       " 'N': 33,\n",
       " 'O': 34,\n",
       " 'P': 35,\n",
       " 'Q': 36,\n",
       " 'R': 37,\n",
       " 'S': 38,\n",
       " 'T': 39,\n",
       " 'U': 40,\n",
       " 'V': 41,\n",
       " 'W': 42,\n",
       " 'Y': 43,\n",
       " 'a': 44,\n",
       " 'b': 45,\n",
       " 'c': 46,\n",
       " 'd': 47,\n",
       " 'e': 48,\n",
       " 'f': 49,\n",
       " 'g': 50,\n",
       " 'h': 51,\n",
       " 'i': 52,\n",
       " 'j': 53,\n",
       " 'k': 54,\n",
       " 'l': 55,\n",
       " 'm': 56,\n",
       " 'n': 57,\n",
       " 'o': 58,\n",
       " 'p': 59,\n",
       " 'q': 60,\n",
       " 'r': 61,\n",
       " 's': 62,\n",
       " 't': 63,\n",
       " 'u': 64,\n",
       " 'v': 65,\n",
       " 'w': 66,\n",
       " 'x': 67,\n",
       " 'y': 68,\n",
       " 'z': 69,\n",
       " 'Ã©': 70}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\t': 0,\n",
       " '\\n': 1,\n",
       " ' ': 2,\n",
       " '!': 3,\n",
       " '$': 4,\n",
       " '%': 5,\n",
       " '&': 6,\n",
       " \"'\": 7,\n",
       " '(': 8,\n",
       " ')': 9,\n",
       " ',': 10,\n",
       " '-': 11,\n",
       " '.': 12,\n",
       " '0': 13,\n",
       " '1': 14,\n",
       " '2': 15,\n",
       " '3': 16,\n",
       " '5': 17,\n",
       " '8': 18,\n",
       " '9': 19,\n",
       " ':': 20,\n",
       " '?': 21,\n",
       " 'A': 22,\n",
       " 'B': 23,\n",
       " 'C': 24,\n",
       " 'D': 25,\n",
       " 'E': 26,\n",
       " 'F': 27,\n",
       " 'G': 28,\n",
       " 'H': 29,\n",
       " 'I': 30,\n",
       " 'J': 31,\n",
       " 'K': 32,\n",
       " 'L': 33,\n",
       " 'M': 34,\n",
       " 'N': 35,\n",
       " 'O': 36,\n",
       " 'P': 37,\n",
       " 'Q': 38,\n",
       " 'R': 39,\n",
       " 'S': 40,\n",
       " 'T': 41,\n",
       " 'U': 42,\n",
       " 'V': 43,\n",
       " 'Y': 44,\n",
       " 'a': 45,\n",
       " 'b': 46,\n",
       " 'c': 47,\n",
       " 'd': 48,\n",
       " 'e': 49,\n",
       " 'f': 50,\n",
       " 'g': 51,\n",
       " 'h': 52,\n",
       " 'i': 53,\n",
       " 'j': 54,\n",
       " 'k': 55,\n",
       " 'l': 56,\n",
       " 'm': 57,\n",
       " 'n': 58,\n",
       " 'o': 59,\n",
       " 'p': 60,\n",
       " 'q': 61,\n",
       " 'r': 62,\n",
       " 's': 63,\n",
       " 't': 64,\n",
       " 'u': 65,\n",
       " 'v': 66,\n",
       " 'x': 67,\n",
       " 'y': 68,\n",
       " 'z': 69,\n",
       " '\\xa0': 70,\n",
       " 'Â«': 71,\n",
       " 'Â»': 72,\n",
       " 'Ã': 73,\n",
       " 'Ã': 74,\n",
       " 'Ã': 75,\n",
       " 'Ã': 76,\n",
       " 'Ã ': 77,\n",
       " 'Ã¢': 78,\n",
       " 'Ã§': 79,\n",
       " 'Ã¨': 80,\n",
       " 'Ã©': 81,\n",
       " 'Ãª': 82,\n",
       " 'Ã«': 83,\n",
       " 'Ã®': 84,\n",
       " 'Ã¯': 85,\n",
       " 'Ã´': 86,\n",
       " 'Ã¹': 87,\n",
       " 'Ã»': 88,\n",
       " 'Å': 89,\n",
       " '\\u2009': 90,\n",
       " 'â': 91,\n",
       " '\\u202f': 92}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_token_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First line from dataset: <br/> [Eng]: Go.     <br/>    [Fre]: &emsp;Va ! <br/>\n",
    "![title](./img/dataset.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16, 71)\n",
      "(10000, 59, 93)\n",
      "(10000, 59, 93)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_data.shape)\n",
    "print(decoder_input_data.shape)\n",
    "print(decoder_target_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One hot representation of \"Go.\" from English:  26 58 8\n",
      "One hot representation of \"\tVa !\" from French :  0 43 45 2 3 1\n",
      "\n",
      "enc_in\tdec_in\tdec_out\n",
      "=============== =======\n",
      "26\t0\t43\n",
      "58\t43\t45\n",
      "8\t45\t2\n",
      "0\t2\t3\n",
      "0\t3\t1\n",
      "0\t1\t2\n",
      "0\t2\t2\n",
      "0\t2\t2\n",
      "0\t2\t2\n",
      "0\t2\t2\n",
      "0\t2\t2\n",
      "0\t2\t2\n",
      "0\t2\t2\n",
      "0\t2\t2\n",
      "0\t2\t2\n",
      "0\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n",
      "\t2\t2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('One hot representation of \"Go.\" from English: ',input_token_index['G'], input_token_index['o'],  input_token_index['.'])\n",
    "print('One hot representation of \"\\tVa !\" from French : ',target_token_index['\\t'],target_token_index['V'], target_token_index['a'],  target_token_index[' '],  target_token_index['!'],  target_token_index['\\n'])\n",
    "\n",
    "print('\\nenc_in\\tdec_in\\tdec_out')\n",
    "print('=============== =======')\n",
    "\n",
    "for i in range(decoder_input_data.shape[1]):\n",
    "    if(i < 16):\n",
    "        print(np.argmax(encoder_input_data[0][i]), end='\\t')\n",
    "    else:\n",
    "        print(end='\\t')\n",
    "    \n",
    "    print(np.argmax(decoder_input_data[0][i]), end='\\t')\n",
    "    print(np.argmax(decoder_target_data[0][i]))\n",
    "\n",
    "len(decoder_target_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So the textdata fits with as follows\n",
    "<b>if, input: </b> Go. <br/>  <b>Output:</b>Va !<br/>\n",
    "It represented as vector like this <br>\n",
    "Go. : [1 2 3, ...........] <br/>\n",
    "Va ! : [2 4 6, ..] \n",
    "\n",
    "<p>\n",
    "And it fitted on model like as follows <br/>\n",
    "    <h1> Model([ eng<sub>t</sub>, Fre<sub>t</sub> ], Fre<sub>t+1</sub>) </h1>\n",
    "</p>\n",
    "\n",
    "<b> Example: <b/>\n",
    "    Model([ [1, 2], [2, 4] ], [4, 6]) <br/> <br/>\n",
    "   So , [ 1 , 2 ], [4]<br/>\n",
    "   &emsp;&nbsp;&nbsp;, [ 2 , 4 ], [6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           (None, None, 71)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           (None, None, 93)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_15 (LSTM)                  [(None, 256), (None, 335872      input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_16 (LSTM)                  [(None, None, 256),  358400      input_14[0][0]                   \n",
      "                                                                 lstm_15[0][1]                    \n",
      "                                                                 lstm_15[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 93)     23901       lstm_16[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 718,173\n",
      "Trainable params: 718,173\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Model([encoder_inputs, decoder_inputs], decoder_outputs).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/5\n",
      "8000/8000 [==============================] - 24s 3ms/step - loss: 0.9763 - accuracy: 0.7429 - val_loss: 0.9715 - val_accuracy: 0.7299\n",
      "Epoch 2/5\n",
      "8000/8000 [==============================] - 24s 3ms/step - loss: 0.7579 - accuracy: 0.7924 - val_loss: 0.7711 - val_accuracy: 0.7796\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - 21s 3ms/step - loss: 0.6256 - accuracy: 0.8198 - val_loss: 0.6737 - val_accuracy: 0.8049\n",
      "Epoch 4/5\n",
      "8000/8000 [==============================] - 22s 3ms/step - loss: 0.5643 - accuracy: 0.8355 - val_loss: 0.6260 - val_accuracy: 0.8204\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 21s 3ms/step - loss: 0.5242 - accuracy: 0.8467 - val_loss: 0.5960 - val_accuracy: 0.8248\n",
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence: Atrenez-vous parter !\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Puis-je monter ?\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Puis-je monter ?\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: ArrÃªte de monter !\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: ArrÃªte de monter !\n",
      "\n",
      "-\n",
      "Input sentence: Who?\n",
      "Decoded sentence: Qui est ent chente ?\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: As-vous ent cous ?\n",
      "\n",
      "-\n",
      "Input sentence: Fire!\n",
      "Decoded sentence: Atrenez-vous !\n",
      "\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: ArrÃªtez de monter !\n",
      "\n",
      "-\n",
      "Input sentence: Jump.\n",
      "Decoded sentence: ArrÃªtez de monter !\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: ArrÃªtez de monter !\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: ArrÃªtez de monter !\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: ArrÃªtez de monter !\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Atrenez-vous !\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Atrenez-vous !\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: ArrÃªtez de monter !\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: ArrÃªtez de monter !\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: ArrÃªtez de monter !\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: ArrÃªtez de monter !\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: ArrÃªtez de monter !\n",
      "\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence: Je suis ent parien.\n",
      "\n",
      "-\n",
      "Input sentence: I try.\n",
      "Decoded sentence: C'est contente.\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Je suis ent chanter.\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Je suis ent chanter.\n",
      "\n",
      "-\n",
      "Input sentence: I won.\n",
      "Decoded sentence: Je suis ent chanter.\n",
      "\n",
      "-\n",
      "Input sentence: Oh no!\n",
      "Decoded sentence: Qui le conte ?\n",
      "\n",
      "-\n",
      "Input sentence: Attack!\n",
      "Decoded sentence: ArrÃªte de monter !\n",
      "\n",
      "-\n",
      "Input sentence: Attack!\n",
      "Decoded sentence: ArrÃªte de monter !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: ArrÃªte de monter !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: ArrÃªte de monter !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: ArrÃªte de monter !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: ArrÃªte de monter !\n",
      "\n",
      "-\n",
      "Input sentence: Get up.\n",
      "Decoded sentence: ArrÃªtez de monter !\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: ArrÃªtez de monter !\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: ArrÃªtez de monter !\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: ArrÃªtez de monter !\n",
      "\n",
      "-\n",
      "Input sentence: Got it!\n",
      "Decoded sentence: ArrÃªtez de monter !\n",
      "\n",
      "-\n",
      "Input sentence: Got it!\n",
      "Decoded sentence: ArrÃªtez de monter !\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: ArrÃªtez de monter !\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: ArrÃªtez de monter !\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: ArrÃªtez de monter !\n",
      "\n",
      "-\n",
      "Input sentence: Hop in.\n",
      "Decoded sentence: ArrÃªte de mont !\n",
      "\n",
      "-\n",
      "Input sentence: Hop in.\n",
      "Decoded sentence: ArrÃªte de mont !\n",
      "\n",
      "-\n",
      "Input sentence: Hug me.\n",
      "Decoded sentence: ArrÃªtez de monter !\n",
      "\n",
      "-\n",
      "Input sentence: Hug me.\n",
      "Decoded sentence: ArrÃªtez de monter !\n",
      "\n",
      "-\n",
      "Input sentence: I fell.\n",
      "Decoded sentence: Je suis ent chanter.\n",
      "\n",
      "-\n",
      "Input sentence: I fell.\n",
      "Decoded sentence: Je suis ent chanter.\n",
      "\n",
      "-\n",
      "Input sentence: I know.\n",
      "Decoded sentence: Je suis ent chanter.\n",
      "\n",
      "-\n",
      "Input sentence: I left.\n",
      "Decoded sentence: Je suis ent chanter.\n",
      "\n",
      "-\n",
      "Input sentence: I left.\n",
      "Decoded sentence: Je suis ent chanter.\n",
      "\n",
      "-\n",
      "Input sentence: I lied.\n",
      "Decoded sentence: Je suis ent chanter.\n",
      "\n",
      "-\n",
      "Input sentence: I lost.\n",
      "Decoded sentence: Je suis ent chanter.\n",
      "\n",
      "-\n",
      "Input sentence: I paid.\n",
      "Decoded sentence: Je suis ent chanter.\n",
      "\n",
      "-\n",
      "Input sentence: I'm 19.\n",
      "Decoded sentence: Je suis ent chanter.\n",
      "\n",
      "-\n",
      "Input sentence: I'm OK.\n",
      "Decoded sentence: Je suis ent chanter.\n",
      "\n",
      "-\n",
      "Input sentence: I'm OK.\n",
      "Decoded sentence: Je suis ent chanter.\n",
      "\n",
      "-\n",
      "Input sentence: Listen.\n",
      "Decoded sentence: ArrÃªte de mont !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: ArrÃªte de monter !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: ArrÃªte de monter !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: ArrÃªte de monter !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: ArrÃªte de monter !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: ArrÃªte de monter !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: ArrÃªte de monter !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: ArrÃªte de monter !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: ArrÃªte de monter !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: ArrÃªte de monter !\n",
      "\n",
      "-\n",
      "Input sentence: Really?\n",
      "Decoded sentence: ArrÃªtez de monter !\n",
      "\n",
      "-\n",
      "Input sentence: Really?\n",
      "Decoded sentence: ArrÃªtez de monter !\n",
      "\n",
      "-\n",
      "Input sentence: Really?\n",
      "Decoded sentence: ArrÃªtez de monter !\n",
      "\n",
      "-\n",
      "Input sentence: Thanks.\n",
      "Decoded sentence: ArrÃªtez de monter.\n",
      "\n",
      "-\n",
      "Input sentence: We try.\n",
      "Decoded sentence: Nous sommes anter.\n",
      "\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: Nous sommes anterres.\n",
      "\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: Nous sommes anterres.\n",
      "\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: Nous sommes anterres.\n",
      "\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: Nous sommes anterres.\n",
      "\n",
      "-\n",
      "Input sentence: Ask Tom.\n",
      "Decoded sentence: At-vous en cous ?\n",
      "\n",
      "-\n",
      "Input sentence: Awesome!\n",
      "Decoded sentence: As-vous en cous ?\n",
      "\n",
      "-\n",
      "Input sentence: Be calm.\n",
      "Decoded sentence: Soyez pastente !\n",
      "\n",
      "-\n",
      "Input sentence: Be calm.\n",
      "Decoded sentence: Soyez pastente !\n",
      "\n",
      "-\n",
      "Input sentence: Be calm.\n",
      "Decoded sentence: Soyez pastente !\n",
      "\n",
      "-\n",
      "Input sentence: Be cool.\n",
      "Decoded sentence: Soyez pastente !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Soyez pastente !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Soyez pastente !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Soyez pastente !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Soyez pastente !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Soyez pastente !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Soyez pastente !\n",
      "\n",
      "-\n",
      "Input sentence: Be kind.\n",
      "Decoded sentence: ArrÃªtez de monter !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Soyez pastente !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Soyez pastente !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Soyez pastente !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Soyez pastente !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Soyez pastente !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Soyez pastente !\n",
      "\n",
      "-\n",
      "Input sentence: Beat it.\n",
      "Decoded sentence: ArrÃªtez de monter !\n",
      "\n",
      "-\n",
      "Input sentence: Call me.\n",
      "Decoded sentence: ArrÃªtez de monter !\n",
      "\n",
      "-\n",
      "Input sentence: Call me.\n",
      "Decoded sentence: ArrÃªtez de monter !\n",
      "\n",
      "-\n",
      "Input sentence: Call us.\n",
      "Decoded sentence: ArrÃªtez de monter !\n",
      "\n",
      "-\n",
      "Input sentence: Call us.\n",
      "Decoded sentence: ArrÃªtez de monter !\n",
      "\n",
      "-\n",
      "Input sentence: Come in.\n",
      "Decoded sentence: ArrÃªtez de monter !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Run training\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)\n",
    "# Save model\n",
    "model.save('s2s1.h5')\n",
    "\n",
    "# Next: inference mode (sampling).\n",
    "# Here's the drill:\n",
    "# 1) encode input and retrieve initial decoder state\n",
    "# 2) run one step of decoder with this initial state\n",
    "# and a \"start of sequence\" token as target.\n",
    "# Output will be the next target token\n",
    "# 3) Repeat with the current target token and current states\n",
    "\n",
    "# Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
